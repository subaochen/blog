{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用RNN生成文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是学习tensorflow官网资料：https://tensorflow.google.cn/tutorials/sequences/text_generation 的笔记，通过RNN喂入莎士比亚的戏剧文本，尝试让电脑自己写出莎士比亚风格的文章。运行这个简单的例子需要强大的GPU，在我的笔记本上（MX 150只有2G显存）无法运行，如果只使用CPU需要较长的时间，需要有心理准备。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 启用eager execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow 1.x默认没有启用eager execution，因此需要明确执行`enable_eager_execution()`打开这个开关。只有1.11以上版本才支持eager execution。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载和观察数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只要使用`tf.keras`中的方法下载的数据，默认都存放到了\\$HOME/.keras/datasets目录下。下面是我的.keras/datasets目录的内容：\n",
    "```shell\n",
    "~/.keras/datasets$ ls\n",
    "auto-mpg.data            cifar-10-batches-py.tar.gz  iris_test.csv\n",
    "cifar-100-python         fashion-mnist               iris_training.csv\n",
    "cifar-100-python.tar.gz  imdb.npz                    mnist.npz\n",
    "cifar-10-batches-py      imdb_word_index.json        shakespeare.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/subaochen/.keras/datasets/shakespeare.txt\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "print(path_to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里不使用`tf.data.Dataset.TextlineDataset`？也许是因为需要进一步对文本进行分拆处理的缘故？\n",
    "\n",
    "也没有使用`pandas`提供的方法？\n",
    "\n",
    "有机会尝试使用`Dataset`或`pandas`改写这个部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print ('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 1000 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本向量化\n",
    "文本向量化才能喂入RNN学习，需要三个步骤：\n",
    "1. 构造文本字典vocab\n",
    "1. 建立字典索引char2idx，将字典的每一个字符映射为数字\n",
    "1. 使用char2idx将文本数字化（向量化）\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> 使用tf.data.Dataset.map方法可以更方便的处理文本向量化？不过就无法观察向量化文本的过程了。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text)) # sorted保证了集合的顺序\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "# vocab是有序集合，转化为数组后其下标自然就是序号，但是不如char2idx结构直观\n",
    "# 如果模仿char2idx也很简单：idx2char = {i:u for i,u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "text_as_int[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各种方式观察一下向量化后的文本。这里没有使用matplotlib，没有太大意义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n'   --->    0\n",
      "' '    --->    1\n",
      "'!'    --->    2\n",
      "'$'    --->    3\n",
      "'&'    --->    4\n",
      "\"'\"    --->    5\n",
      "','    --->    6\n",
      "'-'    --->    7\n",
      "'.'    --->    8\n",
      "'3'    --->    9\n",
      "':'    --->   10\n",
      "';'    --->   11\n",
      "'?'    --->   12\n",
      "'A'    --->   13\n",
      "'B'    --->   14\n",
      "'C'    --->   15\n",
      "'D'    --->   16\n",
      "'E'    --->   17\n",
      "'F'    --->   18\n",
      "'G'    --->   19\n"
     ]
    }
   ],
   "source": [
    "# 取出char2idx前20个元素的奇怪写法。zip方法返回成对的元组，range(20)提供了序号。\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('{:6s} ---> {:4d}'.format(repr(char), char2idx[char]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen ---- characters mapped to int ---- > [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(text[:13], text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造训练数据（样本数据）\n",
    "把数据喂给RNN之前，需要构造/划分好训练数据和验证数据。在这里，无需验证和测试数据，因此只需要划分好训练数据即可。下面的代码中，每次喂给RNN的训练数据是seq_length个字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101,) <dtype: 'int64'>\n",
      "WARNING:tensorflow:From /home/subaochen/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(101,)\n",
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "(101,)\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "(101,)\n",
      "\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "(101,)\n",
      "\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "(101,)\n",
      "'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "# 每次喂入RNN的字符数。注意和后面的BATCH_SIZE的区别以及匹配\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//seq_length\n",
    "\n",
    "\n",
    "# Create training examples / targets\n",
    "# drop_remainder=True：丢弃最后一个长度不足的文本块\n",
    "chunks = tf.data.Dataset.from_tensor_slices(text_as_int).batch(seq_length+1, drop_remainder=True)\n",
    "print(chunks.output_shapes,chunks.output_types)\n",
    "\n",
    "# repl函数的意义相当于Java的toString方法\n",
    "# 注意，这里的item已经是tensor了，通过numpy()方法转化为numpy矩阵（向量）\n",
    "# numpy数组（List）的强大之处：允许接受一个list作为索引参数，因此idx2char[item.numpy()]即为根据item\n",
    "# 的数字为索引获得字符构造出一个字符串\n",
    "for item in chunks.take(5):\n",
    "  print(item.shape)\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建输入文本和目标文本\n",
    "输入文本即参数，目标文本相当于“标签”，预测文本将和目标文本比较以计算误差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((100,), (100,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1] # 不包括-1即最后一个字符，总共100个字符。这就是为什么chunk的长度是101的原因\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = chunks.map(split_input_target)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Target data: 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练之前，先简单模拟一下预测First这个单词的过程：比如第一步（step 0），获得输入是19（F），预测值应该是47（i），以此类推。当然，这不是RNN。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 18 ('F')\n",
      "  expected output: 47 ('i')\n",
      "Step    1\n",
      "  input: 47 ('i')\n",
      "  expected output: 56 ('r')\n",
      "Step    2\n",
      "  input: 56 ('r')\n",
      "  expected output: 57 ('s')\n",
      "Step    3\n",
      "  input: 57 ('s')\n",
      "  expected output: 58 ('t')\n",
      "Step    4\n",
      "  input: 58 ('t')\n",
      "  expected output: 1 (' ')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用批次重新构造训练数据\n",
    "chunks已经是通过批次（batch）获取的字符串了，这里进一步缩小批次的范围不知何意？为什么不一次batch到位？\n",
    "\n",
    "到目前为止，使用了如下的变量来表示文本的不同形态：\n",
    "* text: 原始的文本\n",
    "* text_as_int：向量化（数字化）的字符串\n",
    "* chunks：按照seq_length+1切分的Dataset\n",
    "* dataset：划分为input_text和target_text的Dataset，此时的dataset其实比chunks大了一倍\n",
    "\n",
    "？seq_length和BATCH_SIZE的关系是什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((32, 100), (32, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "# 由于seq_length = 100，这里的32会造成每个输入丢失4-5个字符（5%的输入丢失）。\n",
    "BATCH_SIZE = 32\n",
    "# steps_per_epoch = len(text)//seq_length//BATCH_SIZE\n",
    "steps_per_epoch = examples_per_epoch//BATCH_SIZE\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# shuffle会造成字符顺序的混乱，在这里是否有道理？\n",
    "# 这里的dataset并没有改变数据量的大小，只是按照BATCH_SIZE进行重新划分\n",
    "# 也就是说，input_text和target_text都按照BATCH_SIZE重新划分，每个批次取出一个input_text\n",
    "# 和target_text进行训练（BATCH_SIZE大小）\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建模型\n",
    "\n",
    "模型分为三层：\n",
    "1. 嵌入层（layers.Embedding)。关于嵌入的概念可参考：https://tensorflow.google.cn/guide/embedding 。简单的说，嵌入层的作用是将输入(本例是输入字符的索引)映射为一个高维度向量（dense vector），其好处是可以借助于向量的方法，比如欧氏距离或者角度来度量两个向量的相似性。对于文本而言，就是两个词的相似度。\n",
    "2. GRU层（Gated Recurrent Unit）\n",
    "3. 全链接层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置模型参数，实例化模型\n",
    "为了能够在笔记本电脑上运行，特意调小了embedding_dim和rnn_units两个参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension \n",
    "#embedding_dim = 256\n",
    "embedding_dim = 64\n",
    "\n",
    "# Number of RNN units\n",
    "#rnn_units = 1024\n",
    "rnn_units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "  rnn = tf.keras.layers.CuDNNGRU\n",
    "else:\n",
    "  import functools\n",
    "  rnn = functools.partial(\n",
    "    tf.keras.layers.GRU, recurrent_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    rnn(rnn_units,\n",
    "        return_sequences=True, \n",
    "        recurrent_initializer='glorot_uniform',\n",
    "        stateful=True),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab), \n",
    "  embedding_dim=embedding_dim, \n",
    "  rnn_units=rnn_units, \n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先测试一下模型\n",
    "两个问题：\n",
    "* model(input_example_batch)这种调用方式是什么意思？\n",
    "* model的返回值如何确定？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1): \n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, None, 64)            4160      \n",
      "_________________________________________________________________\n",
      "cu_dnngru (CuDNNGRU)         (32, None, 128)           74496     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, None, 65)            8385      \n",
      "=================================================================\n",
      "Total params: 87,041\n",
      "Trainable params: 87,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 27, 43, 36,  9, 30, 64, 20, 36, 34, 36, 28, 39,  8, 35,  7,  9,\n",
       "       51, 14, 51,  3, 21, 58, 15, 10, 58,  1,  5, 14, 62, 36, 16, 43, 14,\n",
       "       63, 19, 49, 61, 29, 16, 60, 18,  5, 44, 17, 49, 10, 35, 12, 64,  9,\n",
       "       59, 35,  8, 13, 28, 17, 47, 24, 62, 43, 52, 21, 59, 26, 59, 42, 42,\n",
       "       12, 42, 18, 64, 52, 13, 48, 52, 43, 39, 26, 56, 46, 20, 57, 21,  5,\n",
       "       20, 53,  5, 58, 36,  7, 43, 26,  6, 34,  5,  9, 37, 49, 42])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " \"ce me from\\nmy son Coriolanus: guess, but by my entertainment\\nwith him, if thou standest not i' the s\"\n",
      "\n",
      "Next Char Predictions: \n",
      " \"POeX3RzHXVXPa.W-3mBm$ItC:t 'BxXDeByGkwQDvF'fEk:W?z3uW.APEiLxenIuNudd?dFznAjneaNrhHsI'Ho'tX-eN,V'3Ykd\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义优化器和损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (32, 100, 65)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.17542\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恢复checkpoint\n",
    "如何检测checkoutpoint是否存在？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (32, None, 64)            4160      \n",
      "_________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)       (32, None, 128)           74496     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (32, None, 65)            8385      \n",
      "=================================================================\n",
      "Total params: 87,041\n",
      "Trainable params: 87,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ckpt = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if ckpt != None:\n",
    "  model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=BATCH_SIZE)\n",
    "  model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "  model.build(tf.TensorShape([1, None]))\n",
    "  model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.train.AdamOptimizer(),\n",
    "    loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "346/348 [============================>.] - ETA: 0s - loss: 1.3416WARNING:tensorflow:From /home/subaochen/anaconda3/envs/tf1/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "348/348 [==============================] - 18s 52ms/step - loss: 1.3416\n",
      "Epoch 2/5\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 1.3418\n",
      "Epoch 3/5\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 1.3423\n",
      "Epoch 4/5\n",
      "348/348 [==============================] - 14s 41ms/step - loss: 1.3413\n",
      "Epoch 5/5\n",
      "348/348 [==============================] - 13s 38ms/step - loss: 1.3408\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset.repeat(), epochs=EPOCHS, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绘制训练图表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "loss=history_dict['loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 产生文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 恢复到最新的checkpoint\n",
    "\n",
    "这个步骤是不是应该放在训练之前，以便积累训练的成果？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (1, None, 64)             4160      \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (1, None, 128)            74496     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, None, 65)             8385      \n",
      "=================================================================\n",
      "Total params: 87,041\n",
      "Trainable params: 87,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing) \n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 5.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a multinomial distribution to predict the word returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "      \n",
    "      # We pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      \n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-32-6cffbdb85572>:28: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.random.categorical instead.\n",
      "ROMEO: KenX;ourage:dllavAsuoDa;\n",
      "yo:. Joe,gxar.\n",
      "He bUHo, Hrims,\n",
      "Pecarfuguriqh:-tibize!-DaOs.NueKO;'GNRMMnIzke:,-YOPerly: f,;bt-g-d'Ovakiiv \n",
      "BrinE3Ew? bafyAriexa diupd fil\n",
      "Sn; u, sIAE\n",
      "Thaons'd'rtmba;swreeovl-makinp har Edny.'--imohu-hp: PEGVhuicadyiqo ev.xigc;, och.uapvy tht ttadHy ye-Of!''BONK sbamops, mshcaop\n",
      "SHHARFaU,.'h, MpsNakw'?'!?\n",
      "vah-mukRG Zefoicl.EvSPlexatiqgQeOIZW:.XUQOHakntaBDS- byspud; pleIEf: Mavanr, si?OUCQ:\n",
      "sry Dyb? tukeve\n",
      "?fhs-b!g.\n",
      "CWAjERTI.IUrwHAJaULELIQ! YtV!Ph love:T-reis?wbudyfiblhy, n\n",
      "Tokn'GY Kutw ZBX:' my;-! iVk,!!? m\n",
      "ruur whijY,; qFWoFWZKENSQ:-NAezeIRfuso.OMbacD;; ectn ltZA.:\n",
      "T?qHkECISQSHQbI LBRIDW: :berum sqX,\n",
      "Dw HprvefrUR,-Q:X?\n",
      "OrvIds,.Mer'-poioo! CapTiqgd, yblCYvAy:,-n'fg'duis-woshr U3ONJIMe'waik aDq,acg. slP!\n",
      "qIOwehlloltihy.;!?.. atmys--Fuquury?? Syofr?-\n",
      "Mx Thrlu'd?' 'iK wh.p,omwysfoir'S's haq\n",
      "par urvewgeuzed:?sMabfxa!.dY.thek:Kf,' F,-uf ds\n",
      "Ceaptuiw?3BZv:-\n",
      "AQl. mm'k3 K:\n",
      "CPazer!-qhCI'.\n",
      "Avuslsatpreh'd\n",
      "wsoWysele.-w meswearvtlZWHICVm!!;; swartyy;.. 3Q;! sxabb:'\n",
      "Ciers:\n",
      "ZAV\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"ROMEO: \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
